{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyxpdf import Document, Config\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "#import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "import pytesseract\n",
    "import cv2\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(image):\n",
    "    plt.rcParams[\"figure.figsize\"] = (30,30)\n",
    "    plt.imshow(image,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image):\n",
    "    \n",
    "    img_bin = 255 - image\n",
    "    thresh1,img_bin_otsu = cv2.threshold(img_bin,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2))\n",
    "\n",
    "    # Vertical erosion and dilation (for columns)\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, np.array(image).shape[1]//100))\n",
    "    eroded_image = cv2.erode(img_bin_otsu, vertical_kernel, iterations=12)\n",
    "    vertical_lines = cv2.dilate(eroded_image, vertical_kernel, iterations=12)\n",
    "\n",
    "    # Horizontal erosion and dilation (for rows)\n",
    "    hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (np.array(image).shape[1]//100, 1))\n",
    "    horizontal_lines = cv2.erode(img_bin, hor_kernel, iterations=15)\n",
    "    horizontal_lines = cv2.dilate(horizontal_lines, hor_kernel, iterations=15)\n",
    "    \n",
    "    # Combining the vertical and horizontal lines\n",
    "    vertical_horizontal_lines = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0.0)\n",
    "    vertical_horizontal_lines = cv2.erode(~vertical_horizontal_lines, kernel, iterations=3)\n",
    "    thresh, vertical_horizontal_lines = cv2.threshold(vertical_horizontal_lines,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    bitxor = cv2.bitwise_xor(image,vertical_horizontal_lines)\n",
    "    bitnot = cv2.bitwise_not(bitxor)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(vertical_horizontal_lines, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boundingBoxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    (contours, boundingBoxes) = zip(*sorted(zip(contours, boundingBoxes),key=lambda x:x[1][1]))    \n",
    "    boxes = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if (w<1000 and h<500):\n",
    "            image = cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            boxes.append([x,y,w,h])\n",
    "    #display(image)\n",
    "    \n",
    "    # Getting the rows and columns\n",
    "    rows=[]\n",
    "    temp=[]\n",
    "    heights = [boundingBoxes[i][3] for i in range(len(boundingBoxes))] #Bounding box is a list having x,y,w,h\n",
    "    mean = np.mean(heights)\n",
    "    print(len(boxes))\n",
    "    temp.append(boxes[0])\n",
    "    previous=boxes[0]\n",
    "    for i in range(1,len(boxes)):\n",
    "        if(boxes[i][1]<=previous[1]+mean/2):\n",
    "            temp.append(boxes[i])\n",
    "            previous=boxes[i]\n",
    "            if(i==len(boxes)-1):\n",
    "                rows.append(temp)\n",
    "        else:\n",
    "            rows.append(temp)\n",
    "            temp=[]\n",
    "            previous = boxes[i]\n",
    "            temp.append(boxes[i])\n",
    "    total_rows = len(rows)\n",
    "    #print(\"Total rows = \",total_rows)\n",
    "    \n",
    "    # The total columns \n",
    "    total_columns=0\n",
    "    for i in range(total_rows):\n",
    "        if len(rows[i]) > total_columns:\n",
    "            total_columns = len(rows[i])\n",
    "    #print(\"Total columns = \",total_columns)\n",
    "    \n",
    "    # Getting centres of cells and sorting them\n",
    "    center = [int(rows[i][j][0]+rows[i][j][3]/2) for j in range(len(rows[i])) if rows[0]]\n",
    "    center=np.array(center)\n",
    "    center.sort()\n",
    "    #print(center)\n",
    "    \n",
    "    # List of coordinates of the boxes\n",
    "    boxes_list = []\n",
    "    for i in range(len(rows)):\n",
    "        l=[]\n",
    "        for k in range(total_columns):\n",
    "            l.append([])\n",
    "        for j in range(len(rows[i])):\n",
    "            diff = abs(center-(rows[i][j][0]+rows[i][j][2]/total_rows))\n",
    "            minimum = min(diff)\n",
    "            indexing = list(diff).index(minimum)\n",
    "            l[indexing].append(rows[i][j])\n",
    "        boxes_list.append(l)\n",
    "       \n",
    "    # Extracting the text using PyTesseract\n",
    "    final=[]\n",
    "\n",
    "    for i in range(len(boxes_list)):\n",
    "        for j in range(len(boxes_list[i])):\n",
    "            s=''\n",
    "            if(len(boxes_list[i][j])==0):\n",
    "                final.append(' ')\n",
    "            else:\n",
    "                for k in range(len(boxes_list[i][j])):\n",
    "                    y,x,w,h = boxes_list[i][j][k][0],boxes_list[i][j][k][1], boxes_list[i][j][k][2],boxes_list[i][j][k][3]\n",
    "                    roi = bitnot[x:x+h, y:y+w]\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,1))\n",
    "                    border = cv2.copyMakeBorder(roi,2,2,2,2, cv2.BORDER_CONSTANT,value=[255,255])\n",
    "                    resizing = cv2.resize(border, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "                    dilation = cv2.dilate(resizing, kernel,iterations=1)\n",
    "                    erosion = cv2.erode(dilation, kernel,iterations=2)                \n",
    "                    out = pytesseract.image_to_string(erosion)\n",
    "                    s = s +\" \"+ out\n",
    "                final.append(s)\n",
    "    \n",
    "    arr = np.array(final)\n",
    "    arr = arr.reshape(total_rows, total_columns)\n",
    "    print(len(boxes))\n",
    "\n",
    "    return arr,total_rows,total_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 ---------Extracting---------\n",
      "56\n",
      "56\n",
      "Page 2 ---------Extracting---------\n",
      "120\n",
      "120\n",
      "Page 3 ---------Extracting---------\n",
      "120\n",
      "120\n",
      "Page 4 ---------Extracting---------\n",
      "120\n",
      "120\n",
      "Page 5 ---------Extracting---------\n",
      "120\n",
      "120\n",
      "Page 6 ---------Extracting---------\n",
      "120\n",
      "120\n",
      "Page 7 ---------Extracting---------\n",
      "120\n",
      "120\n",
      "Page 8 ---------Extracting---------\n",
      "120\n",
      "120\n",
      "Page 9 ---------Extracting---------\n",
      "120\n",
      "120\n",
      "Page 10 ---------Extracting---------\n",
      "120\n",
      "120\n",
      "Page 11 ---------Extracting---------\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "def get_table(path):\n",
    "    text = []\n",
    "    index = 0\n",
    "    images = convert_from_path(path)\n",
    "    header = ['Value Date','Particulars','Tran Type','Cheque Details','Withdrawals','Deposits','Balance','Dr/Cr']\n",
    "    df = pd.DataFrame(columns=header)\n",
    "    for i in range(len(images)):\n",
    "        print('Page',i+1,'---------Extracting---------')\n",
    "        open_cv_image = np.array(images[i]) \n",
    "        # Convert RGB to BGR \n",
    "        open_cv_image = open_cv_image[:, :, ::-1].copy() \n",
    "        open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "        text,rows,cols = extract_text(open_cv_image)\n",
    "\n",
    "        for r in range(rows):\n",
    "            res = []\n",
    "            for w in text[r]:\n",
    "                res.append(w.replace(\"\\x0c\", \"\"))\n",
    "            df.loc[index] = res\n",
    "            index += 1\n",
    "        \n",
    "    #df = df.style.set_properties(align=\"left\")\n",
    "    df = df.replace(r'\\n',' ', regex=True)\n",
    "    return df\n",
    "    \n",
    "data = get_table('1-4-19 to 30-12-19.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,['Value Date', 'Tran Type', 'Cheque Details', 'Balance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_dict('dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_dict('series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_dict('split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_dict('records') ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(path):\n",
    "    text_data = []\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        page = pdf.pages[0]\n",
    "        text = page.extract_text()\n",
    "        text_data.append(text)\n",
    "    return text_data\n",
    "\n",
    "text1 = get_text('1-4-19 to 30-12-19.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1[0].split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document('1-4-19 to 30-12-19.pdf')\n",
    "t = doc[0].text()\n",
    "Config.load_file(\"\")\n",
    "t = doc[0].text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = t.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "re.split('\\n\\n, :',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.replace(r'\\n\\n', '')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1.split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install slate3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "import pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('1-4-19 to 30-12-19.pdf', 'rb') #load file\n",
    "parser = PDFParser(file) #open pasring object\n",
    "document = PDFDocument(parser) #store parsing object structure and check for password\n",
    "\n",
    "if not document.is_extractable:\n",
    "    print(PDFTextExtractionNotAllowed)\n",
    "\n",
    "rsrcmgr = PDFResourceManager()\n",
    "device = PDFDevice(rsrcmgr)\n",
    "laparams = LAParams()\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_obj(lt_objs):\n",
    "    list1 = []\n",
    "\n",
    "    \n",
    "    for obj in lt_objs:\n",
    "        \n",
    "        if isinstance(obj, pdfminer.layout.LTTextBoxHorizontal):\n",
    "            #print(\"%6d, %6d, %s\" % (obj.bbox[0], obj.bbox[1], obj.get_text().replace('\\n', '')))\n",
    "            list1.append(obj.get_text().replace('\\n', ''))\n",
    "        \n",
    "        \n",
    "        elif isinstance(obj, pdfminer.layout.LTFigure):\n",
    "            parse_obj(obj._objs)\n",
    "    return list1\n",
    "\n",
    "\n",
    "main_list=[]\n",
    "for page in PDFPage.create_pages(document):\n",
    "    interpreter.process_page(page)\n",
    "    layout = device.get_result()\n",
    "    x=parse_obj(layout._objs)\n",
    "    main_list.append(x)\n",
    "print(main_list[0])\n",
    "##(33, 728); (418,727); (33,470); (418,470)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(main_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = main_list[0][:46]\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert(lst):\n",
    "    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)}\n",
    "    return res_dct\n",
    "\n",
    "\n",
    "lst = dict1\n",
    "data_dict = Convert(lst)\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = { x.translate({32:None}) : y \n",
    "                for x, y in data_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
